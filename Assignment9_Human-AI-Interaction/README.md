## Credit Risk Prediction & Explainable AI (SHAP) Project

### Explanation Method 1: Video Explaining SHAP Method to a C-suite Executive (https://duke.box.com/s/pmd3vqdfk9fztq26ns8idsql9l5jlfay)

In this video presentation, I explain the implementation and business impact of SHAP (SHapley Additive exPlanations) for credit risk assessment to senior executives.

I address current challenges faced by financial institutions, including regulatory pressure from the EU's AI Act, inconsistent performance of traditional models, and customer dissatisfaction due to opaque loan decisions. I then introduce SHAP as an effective solution, emphasizing its strengths: transparency, consistency, flexibility across models, and efficiency improvements in decision-making.

The presentation includes interpretations of SHAP visualizations based on our specific predictive model constructed by code tutorial below, highlighting key risk factors such as loan grade, loan-to-income ratio, and homeownership status. For each factor, strategic business actions are detailed, such as stricter approvals and customized repayment plans. The video concludes with a structured implementation roadmap and expected ROI.

### Explanation Method 2: Code Tutorial with Markdown Documentation

The second explanation provided is a detailed code tutorial using Python and SHAP, clearly documented with Markdown. It covers:
- Data loading and preprocessing
- Model training (Decision Tree, Random Forest, XGBoost)
- Hyperparameter tuning and model selection
- Application of SHAP for global and local interpretability

Key visualizations, including the SHAP summary plot and waterfall plot, are explained. This tutorial enables other practitioners to replicate the analysis, understand feature contributions, and communicate the rationale behind model decisions.

### Data Source:
The dataset used for this project is publicly available from Kaggle: [Credit Risk Dataset](https://www.kaggle.com/datasets/laotse/credit-risk-dataset/data)

### Objective
This assignment aims to demonstrate not only technical proficiency in implementing XAI methods but also the ability to effectively communicate complex model decisions to non-technical stakeholders, such as C-suite executives.

---

**Author:** Junyu Zhang  
**Contact:** junyu.zhang@duke.edu


