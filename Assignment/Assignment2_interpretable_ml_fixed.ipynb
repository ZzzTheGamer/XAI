{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ZzzTheGamer/XAI/blob/Assignment/Assignment2_interpretable_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O-qdHvS3lCm"
   },
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QywtMdJp3s6P"
   },
   "source": [
    "## Load the dataset & Take a look at the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8M81VUa31lf"
   },
   "source": [
    "## 1. Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9kxQkFw7xUx"
   },
   "source": [
    "\n",
    "*   Drop 'customerID' column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['customerID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_QObryF73SJ"
   },
   "source": [
    "\n",
    "\n",
    "*   Convert 'TotalCharges' to numeric, replace missing entries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "data.dropna(subset=['TotalCharges'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpDBUv-t8HFe"
   },
   "source": [
    "\n",
    "\n",
    "*   Convert target variable 'Churn' to numeric (0 for No, 1 for Yes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Churn'] = data['Churn'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MMAGIYj8Nlu"
   },
   "source": [
    "\n",
    "\n",
    "*   Encode of categorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwfeJGK48SWO"
   },
   "source": [
    "\n",
    "\n",
    "*   Standardize numeric features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric features for scaling\n",
    "numeric_features = data.select_dtypes(include=[np.number]).columns.drop(['Churn','SeniorCitizen'])\n",
    "\n",
    "# Apply StandardScaler to numeric features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data[numeric_features])\n",
    "\n",
    "# Replace original numeric features with scaled values\n",
    "features_scaled = pd.DataFrame(scaled_features, columns=numeric_features, index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt3RPU_t8bTv"
   },
   "source": [
    "\n",
    "\n",
    "*   Do outlier influence test\n",
    "*   If cook's distance exceeds the threshold, then it is a potential high impact observation point\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the independent variables and target\n",
    "X = data[numeric_features]\n",
    "y = data['Churn']\n",
    "\n",
    "# Add a constant for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cook's Distance\n",
    "influence = model.get_influence()\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "\n",
    "# Visualize Cook's Distance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.stem(range(len(cooks_d)), cooks_d, markerfmt=\",\")\n",
    "plt.axhline(4 / len(X), color='r', linestyle='--', label='Threshold (4/n)')\n",
    "plt.title(\"Cook's Distance\")\n",
    "plt.xlabel(\"Observation Index\")\n",
    "plt.ylabel(\"Cook's Distance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influential_points = np.where(cooks_d > (4 / len(X)))[0]\n",
    "print(f\"High impact point index: {influential_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmEbWAo38_Am"
   },
   "source": [
    "\n",
    "\n",
    "*   However, we will not take any action here because when we look back at the dataset, we find that the numeric data includes tenure and total/monthly charges. For wealthy individuals, their charges can be very high, and such extreme values are meaningful. Ignoring them would risk excluding the wealthy group. Additionally, we have already scaled the data, which helps mitigate the impact of outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQa4E-Qg-h59"
   },
   "source": [
    "\n",
    "\n",
    "*   Combine scaled features with encoded categorical variables and the target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_columns = data.drop(columns=numeric_features).columns\n",
    "data_scaled = pd.concat([features_scaled, data[encoded_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.to_csv('data_scaled_churn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlZ611WK_TLb"
   },
   "source": [
    "## 2. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure binary variables are numeric for correlation computation\n",
    "data_encoded = data_scaled.copy()\n",
    "data_encoded = data_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data_encoded.corr()\n",
    "\n",
    "# Extract correlations with 'Churn' and sort them\n",
    "churn_correlation = correlation_matrix['Churn'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(churn_correlation.index, churn_correlation.values)\n",
    "plt.title('Correlation of Variables with Churn')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Variables')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNr1hrPVAG6p"
   },
   "source": [
    "\n",
    "\n",
    "####   Here we can see how factors may influence the churn rate\n",
    "1.   Negatively correlated variables\n",
    "*   Tenure: Customers who have been with the company longer are less likely to churn, indicating strong customer loyalty.\n",
    "*   Contract_Two year and Contract_One year: Customers with longer-term contracts tend to have lower churn rates.\n",
    "*   TotalCharges: Higher total spending is associated with lower churn, possibly reflecting greater customer loyalty.\n",
    "*   OnlineSecurity_Yes and TechSupport_Yes: Subscribing to additional security services or technical support reduces the likelihood of churn.\n",
    "2.   Positively correlated variables\n",
    "*   PaymentMethod_Electronic check: Customers paying via electronic check have higher churn rates, potentially due to convenience.\n",
    "*   InternetService_Fiber optic: Customers using fiber optic internet services exhibit higher churn rates, possibly due to higher costs.\n",
    "*   MonthlyCharges: Higher monthly charges are linked to increased churn, indicating price-sensitive customers are more likely to leave.\n",
    "*   SeniorCitizen: Older customers show slightly higher churn rates, potentially due to challenges in using technology.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the full correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', cbar=True, square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XNJ08wjCjwk"
   },
   "source": [
    "*    From the overall correlation chart, we can validate the statements above. At the same time, we noticed some ***high correlations*** between non-target variables, which could potentially lead to ***multicollinearity***.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LblhQEMYCvdE"
   },
   "source": [
    "*   Do Vif to test multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Prepare data for VIF calculation (ensure all variables are numeric)\n",
    "X = data_encoded.drop(columns=['Churn'])\n",
    "\n",
    "# Function to calculate VIF\n",
    "def calculate_vif(dataframe):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = dataframe.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
    "    return vif_data\n",
    "vif_data = calculate_vif(X)\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8ADAu4lDHYS"
   },
   "source": [
    "* From the VIF chart, we observe that MonthlyCharges (866.089640) has a very high VIF, which is likely due to strong multicollinearity with TotalCharges.\n",
    "* Additionally, variables such as InternetService_No, OnlineSecurity_No internet service, and OnlineBackup_No internet service show infinite VIF values, which could be influenced by the shared factor of not having internet service, indicating strong multicollinearity.\n",
    "* Similarly, PhoneService_Yes also has a high VIF, suggesting potential multicollinearity with MultipleLines_Yes phone service.\n",
    "* Based on these observations, we will retain one variable from each category while removing other highly collinear variables. We will then recalculate VIF to check if it meets the standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate VIF\n",
    "def calculate_vif(dataframe):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = dataframe.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Step 1: Drop `MonthlyCharges`\n",
    "data_reduced = data_encoded.drop(columns=['MonthlyCharges', 'PhoneService_Yes', 'Churn','OnlineBackup_No internet service',\n",
    "                      'DeviceProtection_No internet service','TechSupport_No internet service',\n",
    "                      'TechSupport_No internet service','StreamingMovies_No internet service',\n",
    "                      'OnlineSecurity_No internet service','StreamingTV_No internet service'], errors='ignore')\n",
    "# Step 2: Recalculate VIF\n",
    "vif_result = calculate_vif(data_reduced)\n",
    "vif_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pSw_dKrFDiV"
   },
   "source": [
    "* Here we can see all values of vif meet the standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgQljvBOFhHc"
   },
   "source": [
    "## 3. Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSOp4nQlFtjG"
   },
   "source": [
    "* Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable and features\n",
    "X = data_reduced\n",
    "y = data_encoded['Churn']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xim023tOFz3F"
   },
   "source": [
    "* Define evaluation function for linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "    for feature, coef in zip(X_train.columns, model.coef_):\n",
    "      print(f\"{feature}: {coef:.4f}\")\n",
    "\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOQ02fljF7FR"
   },
   "source": [
    "* Here we test three linear models: Ordinary linear regression, ridge model, lasso model\n",
    "* For ridge regression: It uses L2 regularization to shrink coefficients, addressing multicollinearity and overfitting while retaining all features.\n",
    "* For lasso regression: It uses L1 regularization to shrink insignificant feature coefficients to zero, enabling feature selection and reducing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "lr_model, lr_pred = evaluate_model(LinearRegression(), X_train, X_test, y_train, y_test, \"Linear Regression\")\n",
    "ridge_model, ridge_pred = evaluate_model(Ridge(alpha=1.0), X_train, X_test, y_train, y_test, \"Ridge Regression\")\n",
    "lasso_model, lasso_pred = evaluate_model(Lasso(alpha=0.01), X_train, X_test, y_train, y_test, \"Lasso Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dui_zPjUJgS5"
   },
   "source": [
    "1. From the summary output, we can see the linear regression model, with an MSE of 0.15 and an R² score of 0.25, explains only 25% of the variance in the target variable, indicating limited predictive power.\n",
    "2. Key insights include that longer tenure and long-term contracts (e.g., one-year and two-year contracts) reduce churn likelihood, while features like fiber-optic internet service and electronic check payments are positively associated with churn. For example, a one-unit increase in tenure decreases churn likelihood by 0.0459, while having InternetService_Fiber optic increases it by 0.1821."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59sYn6-fHoBV"
   },
   "source": [
    "* Here, we defined a function to **check the assumptions** of a linear model, which includes the following assumptions: **Linearity, Homoscedasticity, Normality of Residuals, and Independence**. **Multicollinearity and outliers** have already been detected and corrected earlier, so they are not checked again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from scipy.stats import shapiro\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import linear_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_assumptions(model, X_train, y_train, model_name):\n",
    "    # Predict on the training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    residuals = y_train - y_train_pred\n",
    "\n",
    "    # Linearity: residuals vs. predicted values plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_train_pred, residuals, alpha=0.5)\n",
    "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "    plt.title(f\"Residuals vs. Predicted Values ({model_name})\")\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.show()\n",
    "\n",
    "    # Homoscedasticity: Breusch-Pagan test\n",
    "    X_train_with_const = sm.add_constant(X_train)\n",
    "    bp_test = het_breuschpagan(residuals, X_train_with_const)\n",
    "    bp_test_result = {\n",
    "        \"Lagrange Multiplier Statistic\": bp_test[0],\n",
    "        \"p-value\": bp_test[1],\n",
    "        \"Homoscedasticity\": \"Pass\" if bp_test[1] > 0.05 else \"Fail\",\n",
    "    }\n",
    "\n",
    "    # Normality of residuals: Shapiro-Wilk test\n",
    "    shapiro_test_stat, shapiro_p_value = shapiro(residuals)\n",
    "    shapiro_test_result = {\n",
    "        \"Test Statistic\": shapiro_test_stat,\n",
    "        \"P-Value\": shapiro_p_value,\n",
    "        \"Normality\": \"Pass\" if shapiro_p_value > 0.05 else \"Fail\",\n",
    "    }\n",
    "\n",
    "    # Durbin-Watson rest for independence\n",
    "    durbin_watson_stat = durbin_watson(residuals)\n",
    "\n",
    "    # Display results\n",
    "    assumption_checks = {\n",
    "        \"Breusch-Pagan Test (Homoscedasticity)\": bp_test_result,\n",
    "        \"Shapiro-Wilk Test (Normality)\": shapiro_test_result,\n",
    "        \"Durbin-Watson Test (Independence)\": durbin_watson_stat\n",
    "    }\n",
    "\n",
    "    return assumption_checks\n",
    "\n",
    "# Check assumptions for all three models\n",
    "lr_assumptions = check_assumptions(lr_model, X_train, y_train, \"Linear Regression\")\n",
    "ridge_assumptions = check_assumptions(ridge_model, X_train, y_train, \"Ridge Regression\")\n",
    "lasso_assumptions = check_assumptions(lasso_model, X_train, y_train, \"Lasso Regression\")\n",
    "\n",
    "lr_assumptions, ridge_assumptions, lasso_assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0stvl-KI3ad"
   },
   "source": [
    "* Here, we can see the residual plot shows a clear stratified pattern, indicating that the linearity assumption may not hold. It may due to the binary nature of the target variable or a nonlinear relationship.\n",
    "* The normality and homoscedasticity tests fail, while the independence test holds as the value of the DW test is close to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65c5OmwxKV65"
   },
   "source": [
    "* Below are my solutions. Since the target variable is binary (0 or 1, representing churn or no churn), applying a log transformation to it is neither reasonable nor meaningful. Therefore, I chose to transform the explanatory variables (independent variables). Specifically, I added interaction terms and square terms. These transformations can help address the issues with certain assumptions not being satisfied, such as **linearity**, **homoscedasticity**(nonlinear transformation can reduce the structured pattern of residuals and improve heteroscedasticity), and potentially improving the normality of residuals (the bias can be indirectly reduced, thus increasing the degree of normality satisfaction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate interaction terms (degree=2 includes original features and pairwise interactions)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_interaction = poly.fit_transform(X_train)\n",
    "X_test_interaction = poly.transform(X_test)\n",
    "\n",
    "# Convert the interaction item to a DataFrame\n",
    "interaction_feature_names = poly.get_feature_names_out(X_train.columns)\n",
    "X_train_interaction = pd.DataFrame(X_train_interaction, columns=interaction_feature_names, index=X_train.index)\n",
    "X_test_interaction = pd.DataFrame(X_test_interaction, columns=interaction_feature_names, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_interaction, lr_pred_interaction = evaluate_model(LinearRegression(), X_train_interaction, X_test_interaction, y_train, y_test, \"Linear Regression with Interaction Terms\")\n",
    "ridge_model_interaction, ridge_pred_interaction = evaluate_model(Ridge(alpha=1.0), X_train_interaction, X_test_interaction, y_train, y_test, \"Ridge Regression with Interaction Terms\")\n",
    "lasso_model_interaction, lasso_pred_interaction = evaluate_model(Lasso(alpha=0.01), X_train_interaction, X_test_interaction, y_train, y_test, \"Lasso Regression with Interaction Terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transformed data to DataFrame with consistent feature names\n",
    "X_train_poly = pd.DataFrame(X_train_interaction, columns=interaction_feature_names, index=X_train.index)\n",
    "X_test_poly = pd.DataFrame(X_test_interaction, columns=interaction_feature_names, index=X_test.index)\n",
    "\n",
    "# Pass these updated DataFrames to the assumption-checking function\n",
    "lr_assumptions = check_assumptions(lr_model_interaction, X_train_poly, y_train, \"Linear Regression\")\n",
    "ridge_assumptions = check_assumptions(ridge_model_interaction, X_train_poly, y_train, \"Ridge Regression\")\n",
    "lasso_assumptions = check_assumptions(lasso_model_interaction, X_train_poly, y_train, \"Lasso Regression\")\n",
    "\n",
    "lr_assumptions, ridge_assumptions, lasso_assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate polynomial features (degree=2 includes original and squared terms)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Convert the polynomial features to a DataFrame\n",
    "poly_feature_names = poly.get_feature_names_out(X_train.columns)\n",
    "X_train_poly = pd.DataFrame(X_train_poly, columns=poly_feature_names, index=X_train.index)\n",
    "X_test_poly = pd.DataFrame(X_test_poly, columns=poly_feature_names, index=X_test.index)\n",
    "\n",
    "# Evaluate models with polynomial features\n",
    "lr_model_poly, lr_pred_poly = evaluate_model(LinearRegression(), X_train_poly, X_test_poly, y_train, y_test, \"Linear Regression with Polynomial Features\")\n",
    "ridge_model_poly, ridge_pred_poly = evaluate_model(Ridge(alpha=1.0), X_train_poly, X_test_poly, y_train, y_test, \"Ridge Regression with Polynomial Features\")\n",
    "lasso_model_poly, lasso_pred_poly = evaluate_model(Lasso(alpha=0.01), X_train_poly, X_test_poly, y_train, y_test, \"Lasso Regression with Polynomial Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass these updated DataFrames to the assumption-checking function\n",
    "lr_assumptions = check_assumptions(lr_model_poly, X_train_poly, y_train, \"Linear Regression\")\n",
    "ridge_assumptions = check_assumptions(ridge_model_poly, X_train_poly, y_train, \"Ridge Regression\")\n",
    "lasso_assumptions = check_assumptions(lasso_model_poly, X_train_poly, y_train, \"Lasso Regression\")\n",
    "\n",
    "lr_assumptions, ridge_assumptions, lasso_assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jlN8WE2NAT5"
   },
   "source": [
    "* From this, we can see that even after adding interaction terms and square terms, the performance of the linear model has not significantly improved, and the assumptions are still not satisfied.\n",
    "* To avoid collinearity and improve interpretation, we choose to proceed with the initial model for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient Comparison Plot\n",
    "def plot_coefficients(lr_model, ridge_model, lasso_model):\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Linear': lr_model.coef_,\n",
    "        'Ridge': ridge_model.coef_,\n",
    "        'Lasso': lasso_model.coef_\n",
    "    }, index=X.columns)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    coef_df.plot(kind='bar', width=0.8)\n",
    "    plt.title('Coefficient Comparison: Linear vs Ridge vs Lasso')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Coefficient Value')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_coefficients(lr_model, ridge_model, lasso_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wiaPpXmOFd-"
   },
   "source": [
    "* From this graph, we can see that for the linear regression model, certain features (such as tenure, Contract_Two year, and InternetService_Fiber optic) have larger coefficients, indicating their significant impact on the target variable.\n",
    "* Both Ridge and Lasso retain the importance of these features, but Lasso reduces the coefficients of less significant features (such as PhoneService_Yes and OnlineBackup_Yes) to zero, suggesting these features have lower importance.\n",
    "* The key features identified as important across all models (Linear, Ridge, and Lasso) are tenure, InternetService_Fiber optic, InternetService_No, Contract_One year, and PaymentMethod_Electronic check. Tenure and Contract_One year act as protective features, reducing churn with their negative coefficients, while Fiber optic and Electronic check increase churn risk with positive coefficients. Additionally, InternetService_No is a significant feature indicating that customers without internet service are less likely to churn. These are consistent with those previously found in the correlation matrix section, where more detailed explanations have been explained without attribution explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Heatmap\n",
    "def plot_feature_importance_heatmap(lr_model, ridge_model, lasso_model):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Linear': np.abs(lr_model.coef_),\n",
    "        'Ridge': np.abs(ridge_model.coef_),\n",
    "        'Lasso': np.abs(lasso_model.coef_)\n",
    "    }, index=X.columns)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(importance_df, annot=True, cmap='YlOrRd')\n",
    "    plt.title('Feature Importance Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance_heatmap(lr_model, ridge_model, lasso_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOSXvjJxRp7R"
   },
   "source": [
    "* This heatmap illustrates feature importance across three models (Linear, Ridge, and Lasso). Key features such as **InternetService_Fiber optic, Contract_One year, PaymentMethod_Electronic check, InternetService_No and Tenure** consistently show high importance across all models, indicating their strong influence on churn.\n",
    "* In contrast, less impactful features such as **gender_Male, Dependents_Yes, and OnlineBackup_Yes** are compressed to zero in Lasso. At the same time, for some relatively important variables of the first two models like **total charges and onlineSecurity_yes**, lasso also penalizes their coefficients, making them less important.\n",
    "* Ridge does not change much with respect to linear coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization Path for Lasso\n",
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "# Plot Lasso Regularization Path\n",
    "def plot_lasso_path(X, y, feature_names):\n",
    "    alphas, coefs, _ = lasso_path(X, y, alphas=np.logspace(-5, 2, 200))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for coef_path, feature in zip(coefs, feature_names):\n",
    "        plt.plot(-np.log10(alphas), coef_path, label=feature)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('Coefficients')\n",
    "    plt.title('Lasso Regularization Path')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot\n",
    "plot_lasso_path(X_train, y_train, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obvtNfSSUaoh"
   },
   "source": [
    "* This plot illustrates the Lasso regularization path, showing how feature coefficients change as the regularization strength alpha increases. Key features like **tenure**, **InternetService_Fiber optic**, **Contract_One year**, and **PaymentMethod_Electronic check** retain significant coefficients even under strong regularization, indicating their importance. In contrast, less significant features such as **gender_Male**, **Dependents_Yes**, and **DeviceProtection_Yes** are quickly shrunk to zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWB3j_ZxVGJJ"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYvHCyKLVNl_"
   },
   "source": [
    "* Since the target variable is binary and the linear model fails to meet the required assumptions, using a sigmoid model, such as logistic regression, would be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-I9T_GXVtDT"
   },
   "source": [
    "* Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itlaSsTFW2kp"
   },
   "source": [
    "* Here, we define a unified evaluation model for handling classification problems. The evaluation metrics include **accuracy, precision, recall, F1 score, and ROC AUC value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, threshold=0.5):\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        # Models with probability output\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        # Models with direct prediction output\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # ROC and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} ROC Curve (AUC = {roc_auc_value:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1, label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Return evaluation metrics\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc_value,\n",
    "        \"Confusion Matrix\": conf_matrix.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_eval = evaluate_model(logistic_model, X_train, X_test, y_train, y_test, \"Logistic Regression\")\n",
    "print(logistic_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6Qn8YrWXeLh"
   },
   "source": [
    "1. This ROC curve and evaluation metrics reflect the performance of the logistic regression model on a classification task.\n",
    "2. The ROC curve shows the model's ability to distinguish between positive and negative classes at different thresholds, with an AUC score of 0.83, indicating good discriminatory power (an 83% probability of correctly distinguishing between positive and negative samples).\n",
    "3. The model achieves an accuracy of 78.9%, meaning it correctly predicts 78.9% of all samples. However, the precision (62.5%) indicates that only 62.5% of the samples predicted as positive are actual positives, while the recall (51.3%) reveals that the model identifies only 51.3% of all true positives, suggesting room for improvement in detecting positive cases.\n",
    "4. The F1 score (56.4%) balances precision and recall. The F1 Score is not high, indicating that the model still has room for improvement in the prediction of positive samples.\n",
    "5. To improve, strategies like adjusting the decision threshold to enhance recall, optimizing feature engineering, balancing the dataset to handle potential class imbalance, or exploring more complex models like random forests or gradient boosting can be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocfoSMudYj0O"
   },
   "source": [
    "* **Logistic regression assumption checks (influential outliers and multicollinearity were tested earlier)**\n",
    "* **Test for linearity assumption and converge assumption**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a log interaction for the Box-Tidwell Test\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "X_train_log = X_train_scaled.copy()\n",
    "\n",
    "for col in X_train.columns:\n",
    "    X_train_log[f\"{col}_log\"] = X_train_scaled[col] * np.log(np.abs(X_train_scaled[col] + 1e-10))\n",
    "\n",
    "# Fit the model using statsmodels\n",
    "X_train_log.index = y_train.index\n",
    "X_train_log = sm.add_constant(X_train_log)\n",
    "logit_model = sm.Logit(y_train, X_train_log).fit()\n",
    "\n",
    "# Check the significance level and converge information\n",
    "print(logit_model.summary())\n",
    "print(logit_model.mle_retvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yozJev6qgyqX"
   },
   "source": [
    "##### Here we check the linearity assumption:\n",
    "The linearity assumption in logistic regression suggests that independent variables should have a linear relationship with the log-odds of the dependent variable. To verify this, log interaction terms (e.g., tenure_log, TotalCharges_log) were added, and their p-values were examined. Variables like tenure and TotalCharges had p-values < 0.05 for their log interactions, indicating nonlinearity and the need for transformations. Other variables, such as SeniorCitizen and gender_Male, had non-significant log interactions (p-values of NaN or 1), suggesting they might satisfy the linearity assumption but contribute little to the model. Therefore, transformations are necessary to improve the model fit.\n",
    "\n",
    "##### We also observe the following issues:\n",
    "1. Maximum Likelihood optimization failed to converge.\n",
    "2. Coefficients and standard errors of some variables (e.g., SeniorCitizen) are NaN.\n",
    "3. warnflag: 1 and converged: False.\n",
    "4. These indicate that the model failed to converge within the maximum number of iterations, likely due to the following reasons (should check and address further):\n",
    "Perfect separation: Some variables might perfectly predict the target class, causing coefficient divergence. Insufficient iterations: The default maximum iteration limit may not be adequate for the model to converge High-dimensional features: The number of features relative to the data size may make optimization challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnnY393Pfaa-"
   },
   "source": [
    "* **Test for perfect separation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    print(f\"{col}: {data_encoded.groupby(col)['Churn'].nunique().max()} unique values in target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD8IIII5jtra"
   },
   "source": [
    "###### The fact that each independent variable (col) corresponds to 2 unique values in the target variable (Churn), rather than 1, indicates that there is no perfect separation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWx6qdk7kFT-"
   },
   "source": [
    "* **Test for independence of observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual calculation\n",
    "residuals = y_train - logistic_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Durbin-Watson test\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print(f\"Durbin-Watson Statistic: {dw_stat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF7DJAUZfkdi"
   },
   "source": [
    "###### The Durbin-Watson statistic of 1.995 is very close to 2, which indicates that the residuals of your logistic regression model are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4Ct83tZfSXL"
   },
   "source": [
    "* **Test for large sample size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the number of positive and negative samples is sufficient\n",
    "positive_count = sum(y_train == 1)\n",
    "negative_count = sum(y_train == 0)\n",
    "num_predictors = X_train.shape[1]\n",
    "\n",
    "print(f\"Positive samples: {positive_count}\")\n",
    "print(f\"Negative samples: {negative_count}\")\n",
    "print(f\"Required minimum samples per class: {10 * num_predictors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U-bGLtClOsr"
   },
   "source": [
    "###### We can see the current sample distribution (number of positive and negative samples, both of which are smaller than the minumum number required per class) meets the sample size requirements of logistic regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0UwYBs6p2Rx"
   },
   "source": [
    "* **Test for class imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class distribution\n",
    "class_counts = y_train.value_counts()\n",
    "# Calculate and display proportions\n",
    "class_proportions = class_counts / len(y_train)\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoSvMBswqvgs"
   },
   "source": [
    "###### This indicates a class imbalance, as the majority class (Non-Churn) accounts for nearly three-fourths of the data, while the minority class (Churn) makes up only about one-fourth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aNqVlcgqLh5"
   },
   "source": [
    "###### Here we use weighted logistic regression with class_weight='balanced to refine the model. It helps address the issue of imbalanced class distribution by assigning higher weights to the minority class and lower weights to the majority class. While it does not directly resolve assumptions like linearity or independence, it mitigates the perfect separation issue that can arise when the minority class is underrepresented. Additionally, it indirectly improves model stability by making the loss function more sensitive to underrepresented samples, thereby addressing convergence challenges in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Use weighted logistic regression\n",
    "logistic_model_weighted = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000, class_weight='balanced')\n",
    "logistic_model_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Check weighted model\n",
    "y_pred_weighted = logistic_model_weighted.predict(X_test)\n",
    "print(\"\\nConfusion Matrix (Weighted):\")\n",
    "print(confusion_matrix(y_test, y_pred_weighted))\n",
    "print(\"\\nClassification Report (Weighted):\")\n",
    "print(classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELsmApbNejRX"
   },
   "source": [
    "1. From the graph, we can see the unweighted logistic regression model achieves higher accuracy (78.9%) and precision (62.5%) compared to the weighted model (73% accuracy and 50% precision). This is because the unweighted model prioritizes the majority negative class (non-churn), resulting in fewer false positives (115 vs. 299).\n",
    "2. However, the weighted model significantly improves recall for the positive class (churn), increasing it from 51.3% to 79%, which reduces false negatives (182 to 78).\n",
    "3. The F1 score of the weighted model (61%) is higher than the unweighted model's (56.4%), as it balances the trade-off between precision and recall better for the positive class.\n",
    "4. While the unweighted model is more precise and overall accurate, the weighted model is better at identifying churned customers, making it suitable when minimizing churn is the priority despite more false alarms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZb5vusfrPpf"
   },
   "source": [
    "* **Visualize logistic regression coefficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': logistic_model_weighted.coef_[0]\n",
    "})\n",
    "\n",
    "# Sort coefficients by absolute value\n",
    "coefficients = coefficients.reindex(coefficients['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "coefficients.plot(kind='barh', x='Feature', y='Coefficient', legend=False, color='skyblue')\n",
    "plt.axvline(0, color='black', linewidth=0.8)\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(X_train.columns, logistic_model_weighted.coef_[0]):\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRrUARcXtKLP"
   },
   "source": [
    "1. The plot highlights key features influencing churn. Positive coefficients identify factors increasing churn risk ( increase the likelihood of the target being 1), while negative coefficients point to factors reducing churn. For example, TotalCharges, InternetService_Fiber optic, and PaymentMethod_Electronic check have positive coefficients, indicating that these features are associated with a higher probability of churn.  Contract_Two year, tenure, and OnlineSecurity_Yes have negative coefficients, meaning they are associated with a lower likelihood of churn.\n",
    "2. Features with larger absolute values have the stronger impact on customer behavior. Larger absolute values (e.g., Contract_Two year, tenure) indicate stronger influence on the target. Smaller absolute values (e.g., gender_Male, DeviceProtection_Yes) have minimal impact on predicting churn.\n",
    "3. In more details, if we use numerical variables interpretation by odds, for example, we could say increasing tenure by 1 unit decreases the odds of churn by a factor of exp(−1.3430)≈0.261, meaning the odds of churn reduce by approximately 73.9% per additional unit of tenure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpfcXfR9vTBn"
   },
   "source": [
    "## GAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import LinearGAM, GammaGAM, s\n",
    "# Make sure X_train and y_train are NumPy arrays\n",
    "X_train = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "y_train = y_train.values if hasattr(y_train, 'values') else y_train\n",
    "\n",
    "# The formula of dynamically constructing GAM\n",
    "num_features = X_train.shape[1]\n",
    "# Initializes the first smoothing term\n",
    "formula = s(0)\n",
    "for i in range(1, num_features):\n",
    "    # Add smooth entries dynamically\n",
    "    formula += s(i)\n",
    "\n",
    "# Initialize the GAM model\n",
    "gam = LinearGAM(formula)\n",
    "\n",
    "# Grid search smoothing parameters\n",
    "gam.gridsearch(X_train, y_train)\n",
    "\n",
    "# Fit model\n",
    "gam.fit(X_train, y_train)\n",
    "\n",
    "# Generate prediction\n",
    "y_pred_gam = gam.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which feature corresponds to each s\n",
    "feature_names = data_reduced.columns.to_list()\n",
    "for i, feature in enumerate(feature_names):\n",
    "    print(f\"s({i}) corresponds to feature: {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yBGWyDd1ohn"
   },
   "source": [
    "1. The results of the Generalized Additive Model (GAM) provide insights into the relationship between each feature and customer churn, which accounts for nonlinear effects.\n",
    "2. Key significant features (e.g., tenure, TotalCharges, SeniorCitizen, MultipleLines_Yes, InternetService_Fiber optic, InternetService_No, and contract types...) demonstrate strong statistical significance (p-values close to zero), suggesting they are crucial predictors of churn. For instance, tenure has a highly nonlinear relationship with churn, where longer tenures significantly reduce churn risk. Similarly, customers with longer contracts (one-year or two-year) show much lower churn likelihood compared to those without contracts.\n",
    "3. On the other hand, non-significant features such as gender, whether a customer has dependents, or some payment methods (e.g., credit card automatic payment) exhibit little to no influence on churn, reflecting their limited explanatory power in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz8kwizp2-j8"
   },
   "source": [
    "*  **Visualize GAM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTIozVQcvbOK"
   },
   "source": [
    "###### The below code snippet rows = math.ceil(num_features / 3), plt.figure(figsize=(15, 5 * rows)) were generated using chatgpt4 on 01/17/25 at 8:10pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Determine the number of rows and columns for subplots\n",
    "num_features = len(feature_names)\n",
    "rows = math.ceil(num_features / 3)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * rows))\n",
    "subplot_index = 1\n",
    "for i, term in enumerate(gam.terms):\n",
    "    if term.isintercept:\n",
    "        continue\n",
    "    plt.subplot(rows, 3, subplot_index)\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    plt.plot(XX[:, term.feature], gam.partial_dependence(term=i, X=XX))\n",
    "    plt.title(feature_names[term.feature])\n",
    "    plt.ylabel('Partial dependence')\n",
    "    plt.xlabel(feature_names[term.feature])\n",
    "    subplot_index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ap5DJD05mL1"
   },
   "source": [
    "1. From the graph, we can see each subplot shows how the feature on the x-axis affects the  probability of the target when other features are held constant.\n",
    "2. For features like tenure and TotalCharges, the curves are smooth, showing the non-linear relationship between the feature and the target. Take Tenure as an example, a non-linear effect is observed where low values contribute positively, but higher values decrease the predicted target probability after a point.\n",
    "3. For binary features, the graph shows a simple stepwise change between 0 and 1. Take InternetService_Fiber optic as an example, having fiber optic service seems to increase the predicted probability of the target.\n",
    "4. We can determine the importance of feature according to the value change of the vertical axis. For example, features like tenure, TotalCharges, InternetService_Fiber optic, and Contract_years have substantial impacts on predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAM_eval = evaluate_model(gam, X_train, X_test, y_train, y_test, \"GAM model\")\n",
    "print(GAM_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cL74sfrc_PWK"
   },
   "source": [
    "###### We can see there are some differencces between Gam and logistic model(weighted)\n",
    "1. Precision: GAM achieves higher precision for the positive class (0.6518 vs. 0.50), meaning it is more cautious about predicting positive churn, reducing false positives.\n",
    "2. Recall: Weighted logistic regression excels in recall (0.79 vs. 0.4305), capturing more true positives but at the cost of higher false positives.\n",
    "3. Accuracy: GAM has a slightly higher overall accuracy (0.7875 vs. 0.73).\n",
    "4. F1 Score: Weighted logistic regression has a higher F1 score for the positive class (0.61 vs. 0.5185), making it better at balancing precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg-rgVmUBgvn"
   },
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtzcshFnBnkA"
   },
   "source": [
    "1. Linear Regression (including Ridge and Lasso):\n",
    "* Strengths: (1) Predictions are transparent and easy to interpret as coefficients represent the linear relationship between features and the target variable. (2) Lasso regression helps with feature selection by shrinking less important feature coefficients to zero. (3) Ridge and Lasso can also address overfitting by penalizing large coefficients.\n",
    "* Weaknesses: (1) Linear regression assumes relationships between features and the target are linear, which is often unrealistic in real-world problems like customer churn. In addition, it has to satisfy many conditional assumptions and statistical distribution assumptions, such as Homoscedasticity, Normality etc. (2) It has poor performance for nonlinear data. When relationships are complex (like relationships in this dataset), accuracy decreases. (3) The interpretation of a weight depends on other features being held constant.\n",
    "2. Logistic Regression (Iincluding Weighted Logistic Regression)\n",
    "* Strengths: (1) Easy to interpret, though weights are multiplicative (log-odds). (2) The weighted version helps mitigate imbalanced datasets by assigning different penalties to classes. (3) Provides probabilities in addition to classifications, aiding in decision-making. (4) Performs best among the three models for the variable of interest to us (churn=1), with the highest recall rate and f1 score.\n",
    "* Weakness: (1) Like linear regression, logistic regression is subject to many condition. For example, it assumes linear relationships between features and the log-odds of the target variable. (2) Features that perfectly separate classes can prevent model convergence.\n",
    "3. GAM (Generalized Additive Model)\n",
    "* Strengths: (1) Captures nonlinear relationships between features and the target variable, improving predictive performance. (2) Retains partial transparency by allowing visualization of the effect of each feature on the target. (3) Has the highest predictive power due to its highest accuracy of the three models\n",
    "* Weakness: (1) More computationally intensive and less interpretable than linear models. (2) Requires careful tuning of smoothing parameters to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X54Wf6Y_AA_J"
   },
   "source": [
    "## Recommondations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4ifXrkGFt2G"
   },
   "source": [
    "#### The following models are recommended in order\n",
    "1. When the priority is to identify as many churners as possible while requiring a certain level of interpretability. Use Weighted Logistic Regression. It handles imbalanced data well and is straightforward to explain to stakeholders. Additionally, it performs well in predicting the variables we are most interested in.\n",
    "2. For overall predictive power, use GAM. It can model complex, nonlinear relationships, making it more accurate for overall customer churn prediction.\n",
    "3. Linear regressiona are not recommended as the primary approach due to its inability to handle nonlinear patterns and poor predictive power. However, lasso can be used for feature selection to identify important predictors.\n",
    "#### In addition to the models already explored, several other options can be applied to the customer churn dataset, depending on priorities such as accuracy, interpretability, and complexity. For predictive performance, Gradient Boosting models like XGBoost or Random Forests are excellent choices, as they handle non-linear relationships effectively. If interpretability is crucial, Decision Trees can also provide clear insights into churn drivers. For smaller datasets, Bayesian Models or SVMs may be useful. Meanwhile, Neural Networks are a powerful option for large datasets. Overall, the choice of the model should align with business goals."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
