{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ZzzTheGamer/XAI/blob/Assignment5_Explainable_Deep_Learning/Explainable_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kezUOWKN0rLR"
   },
   "source": [
    "# Below is my experimental design before testing begins ▶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyLmGrUt0Fwo"
   },
   "source": [
    "### **Hypothesis**\n",
    "\n",
    "**H0:** For images labeled as \"airplane\" in the Pascal VOC 2012 dataset, the ResNet-50 model does not exhibit a statistically significant difference in its Grad-CAM activation between the foreground ( the segmented airplane region) and the background region during classification.\n",
    "\n",
    "**H1:** For images labeled as \"airplane\" in the Pascal VOC 2012 dataset, the ResNet-50 model exhibits a statistically significant difference in its Grad-CAM activation between the foreground and the background region during classification. Specifically, it learns the concept \"airplane\" but not the concept \"background\".\n",
    "\n",
    "### **Study Design**\n",
    "\n",
    "1. **Define concepts**\n",
    "\n",
    "- **Target class:** \"aeroplane\" as defined in the Pascal VOC 2012 dataset.\n",
    "\n",
    "- **Concepts to test:**\n",
    "\n",
    "  - **1:** \"Foreground\" – the segmented region corresponding to the airplane.\n",
    "\n",
    "  - **2:** \"Background\" – the remainder of the image outside the airplane segmentation.\n",
    "\n",
    "- **Rationale behind the design:** If ResNet-50 has truly learned to recognize airplanes, its Grad-CAM heatmaps should display more pronounced activation in the airplane region compared to the background. This would confirm that the model's decision-making is driven by the object's defining features rather than by contextual artifacts.\n",
    "\n",
    "2. **Dataset preparation**\n",
    "\n",
    "- **Annotations:**\n",
    "  - Use existing segmentation masks provided for the airplane region as the foreground.\n",
    "  - Define the background as all image regions outside the segmented airplane.\n",
    "\n",
    "3. **Grad-CAM implementation**\n",
    "\n",
    "- **Model:** ResNet-50 pretrained on ImageNet.\n",
    "- **Grad-CAM setup:**\n",
    "  - Extract Grad-CAM heatmaps for the target class for each image.\n",
    "  - Use the final convolutional layer as the source for the activation maps.\n",
    "\n",
    "4. **Quantify activation intensity**\n",
    "\n",
    "- **Metric:** Compute the mean Grad-CAM activation value within each annotated region (foreground vs background).\n",
    "- **Calculation:**\n",
    "  - For each image, compute:\n",
    "    - **MeanActivation<sub>foreground</sub>** = (1 / *N*<sub>pixels_in_foreground</sub>) × ∑ (Grad-CAM values in the airplane region)\n",
    "    - **MeanActivation<sub>background</sub>** = (1 / *N*<sub>pixels_in_background</sub>) × ∑ (Grad-CAM values in the background)\n",
    "    - **Normalization:** Normalize activation values to mitigate variability in absolute heatmap intensities.\n",
    "\n",
    "5. **Statistical Analysis**\n",
    "\n",
    "- **Paired t-test:** Compare **MeanActivation<sub>foreground</sub>** vs **MeanActivation<sub>background</sub>** across all selected images.\n",
    "\n",
    "- **Cohen’s d:** Compute Cohen’s d to quantify the magnitude of the difference between the two regions.\n",
    "\n",
    "- **Null hypothesis rejection:** If *p* < 0.05 and **MeanActivation<sub>foreground</sub>** > **MeanActivation<sub>background</sub>**, reject H0 in favor of H1.\n",
    "\n",
    "6. **Interpretability check**\n",
    "\n",
    "- Visualize Grad-CAM heatmaps for select images where the model shows a pronounced difference in activation between the foreground and background to qualitatively assess the findings.\n",
    "\n",
    "- Investigate potential biases such as segmentation inaccuracies and background artifacts that might influence the results.\n",
    "\n",
    "### **Key Challenges/Limitations**\n",
    "\n",
    "- Segmentation masks in the original dataset may not accurately or consistently delineate airplane regions from the background.\n",
    "- Grad-CAM heatmap might blur into adjacent regions, potentially confounding foreground and background measurements.\n",
    "- It's difficult to manage differences in airplane sizes, positions, and the complexity of backgrounds across images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XULgSt3v0ULE"
   },
   "source": [
    "# Next comes the part that tests the hypothesis ▶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "# Decompressing dataset\n",
    "!tar -xvf VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uApwovzbqwlF"
   },
   "source": [
    "### **Step 1：Initialization** ( images, Grad-CAM class, preprocessing image function )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2E7grklssKgj"
   },
   "source": [
    "* Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for VOC 2012 images and segmentation masks (You can download it from the original code block)\n",
    "# Here, JPEGImages contains the raw RGB images.\n",
    "# SegmentationClass contains the corresponding pixel-level segmentation masks.\n",
    "image_dir = './VOCdevkit/VOC2012/JPEGImages/'\n",
    "mask_dir  = './VOCdevkit/VOC2012/SegmentationClass/'\n",
    "\n",
    "# List image files (they have .jpg or .png extensions)\n",
    "image_files = [fname for fname in os.listdir(image_dir) if fname.lower().endswith(('.jpg', '.png'))] # refined chatgpt-4o on 2/5/2025 at 6:02pm\n",
    "image_files = sorted(image_files)\n",
    "print(f\"total number of {len(image_files)} images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2FMZFwjsMy7"
   },
   "source": [
    "* Define GradCAM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        \"\"\"\n",
    "        Initialize the GradCAM class, store the model and target layer, and register forward and backward hooks.\n",
    "        \"\"\"\n",
    "        # Store the model\n",
    "        self.model = model\n",
    "        # Store the target layer\n",
    "        self.target_layer = target_layer\n",
    "        # Store gradients captured during backpropagation\n",
    "        self.gradients = None\n",
    "        # Store activations captured during forward pass\n",
    "        self.activations = None\n",
    "        # Store hook\n",
    "        self.hook_handles = []\n",
    "        # Register the hooks\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        \"\"\"\n",
    "        Register forward and backward hooks on the target layer to capture activations and gradients.\n",
    "        \"\"\"\n",
    "        # Forward hook: capture the activations of the target layer\n",
    "        self.hook_handles.append(\n",
    "            self.target_layer.register_forward_hook(self.forward_hook)\n",
    "        )\n",
    "        # Backward hook: capture the gradients of the target layer\n",
    "        self.hook_handles.append(\n",
    "            self.target_layer.register_backward_hook(self.backward_hook)\n",
    "        )\n",
    "\n",
    "    def forward_hook(self, module, input, output):\n",
    "        \"\"\"\n",
    "        Forward hook function: capture the output activations during the forward pass.\n",
    "        \"\"\"\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def backward_hook(self, module, grad_in, grad_out):\n",
    "        \"\"\"\n",
    "        Backward hook function: capture the gradients during the backward pass.\n",
    "        \"\"\"\n",
    "        self.gradients = grad_out[0].detach()\n",
    "\n",
    "    def generate(self, input_tensor, target_class):\n",
    "        \"\"\"\n",
    "        Generate the Grad-CAM heatmap:\n",
    "        1. Perform forward pass to obtain the output.\n",
    "        2. Compute gradients for the target class.\n",
    "        3. Apply global average pooling on the gradients to obtain weights.\n",
    "        4. Compute the weighted sum of activations, apply ReLU, upsample, and normalize to [0,1].\n",
    "        \"\"\"\n",
    "        # Clear existing gradients\n",
    "        self.model.zero_grad()\n",
    "        # Forward pass\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        # Extract the logit score for the target class\n",
    "        score = output[0, target_class]\n",
    "\n",
    "        # Backpropagate to compute gradients\n",
    "        score.backward(retain_graph=True)\n",
    "\n",
    "        # Perform global average pooling on the gradients\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "        # Compute the weighted sum of the activations: multiply weights with activations and sum across channels\n",
    "        grad_cam_map = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        # Apply ReLU to keep only positive values\n",
    "        grad_cam_map = F.relu(grad_cam_map)\n",
    "        # Upsample the grad-cam map to the input image size\n",
    "        grad_cam_map = F.interpolate(grad_cam_map, size=input_tensor.shape[2:], mode='bilinear', align_corners=False) # use chatgpt-4o on 2/5/2025 at 7:11pm\n",
    "\n",
    "        # Normalize the heatmap to the range [0, 1]\n",
    "        heatmap = grad_cam_map.squeeze().cpu().numpy()\n",
    "        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "        return heatmap\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        \"\"\"\n",
    "        Remove all registered hooks to prevent memory leaks.\n",
    "        \"\"\"\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIQQZZAzsSg_"
   },
   "source": [
    "* Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing image function\n",
    "# Preprocess the original image\n",
    "transform = transforms.Compose([\n",
    "    # Resize the image to 224x224 pixels\n",
    "    transforms.Resize((224, 224)),\n",
    "    # Convert the image to a tensor and scale pixel values to [0, 1]\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "               std =[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Preprocess the segmentation mask image\n",
    "mask_transform = transforms.Compose([\n",
    "    # Resize the mask to have a short edge of 256 pixels using nearest neighbor interpolation\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.NEAREST),# use chatgpt-4o on 2/5/2025 at 7:25pm\n",
    "    # Center-crop a 224x224 region from the resized mask\n",
    "    transforms.Resize((224, 224))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcA2zKYkrQdi"
   },
   "source": [
    "### **Step 2**: Load pretrained ResNet-50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# For ResNet-50, select the target layer as the last convolutional layer\n",
    "target_layer = model.layer4[-1].conv3\n",
    "# Create an instance of GradCAM with the model and target layer\n",
    "grad_cam = GradCAM(model, target_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_pr_yMGriUV"
   },
   "source": [
    "### **Step 3**: Iterate through images and compute Grad-CAM heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target class index(airplane)\n",
    "target_class = 404\n",
    "\n",
    "# Label index for airplane in VOC segmentation annotations\n",
    "voc_airPlane_label = 1\n",
    "\n",
    "# Lists to store the average activation values for the foreground and background\n",
    "foreground_activation_means = []\n",
    "background_activation_means = []\n",
    "\n",
    "# List to store some visualization examples for later display\n",
    "visualization_examples = []\n",
    "\n",
    "# Loop through all images\n",
    "for fname in image_files:\n",
    "    img_path = os.path.join(image_dir, fname)\n",
    "    mask_path = os.path.join(mask_dir, os.path.splitext(fname)[0] + '.png') # use chatgpt-4o on 2/5/2025 at 7:33pm\n",
    "\n",
    "     # Check if the corresponding segmentation mask exists\n",
    "    if not os.path.exists(mask_path):\n",
    "        continue\n",
    "\n",
    "    # Load the image and convert it to RGB format\n",
    "    original_img = Image.open(img_path).convert('RGB')\n",
    "    # Load the segmentation mask\n",
    "    mask_img = Image.open(mask_path)\n",
    "\n",
    "    # Resize the mask to the same size as the model input\n",
    "    mask_img_resized = mask_transform(mask_img)\n",
    "    mask_np = np.array(mask_img_resized)\n",
    "\n",
    "    # Check whether the image contain a sufficient airplane region( here we use threshold 0.2)\n",
    "    if np.sum(mask_np == voc_airPlane_label) / mask_np.size < 0.2:\n",
    "      continue\n",
    "\n",
    "    # Create a binary foreground mask: values will be 1 for foreground and 0 for background\n",
    "    foreground_mask = (mask_np == voc_airPlane_label).astype(np.uint8)\n",
    "\n",
    "    # Preprocess the image\n",
    "    input_tensor = transform(original_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Generate the Grad-CAM heatmap\n",
    "    heatmap = grad_cam.generate(input_tensor, target_class)\n",
    "\n",
    "    # Compute the average activation values within the foreground and background regions\n",
    "    foreground_vals = heatmap[foreground_mask == 1]\n",
    "    background_vals = heatmap[foreground_mask == 0]\n",
    "\n",
    "    # Skip this image if either the foreground or background region is empty\n",
    "    if foreground_vals.size == 0 or background_vals.size == 0:\n",
    "        continue\n",
    "\n",
    "    # Calculate the mean activation values for the foreground and background regions\n",
    "    mean_foreground = np.mean(foreground_vals)\n",
    "    mean_background = np.mean(background_vals)\n",
    "\n",
    "    # Append the computed mean activation values to their respective lists\n",
    "    foreground_activation_means.append(mean_foreground)\n",
    "    background_activation_means.append(mean_background)\n",
    "\n",
    "    # Save some examples\n",
    "    visualization_examples.append({\n",
    "        'filename': fname,\n",
    "        'original': original_img,\n",
    "        'heatmap': heatmap,\n",
    "        'mask': foreground_mask\n",
    "    })\n",
    "\n",
    "print(f\"Totally {len(foreground_activation_means)} images processed that contain airplane segmentation annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrP1XH78scEH"
   },
   "source": [
    "### **Step 4**: Perform paired t-test on foreground vs. background activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists of foreground and background activation means to NumPy arrays\n",
    "foreground_vals = np.array(foreground_activation_means)\n",
    "background_vals = np.array(background_activation_means)\n",
    "\n",
    "# Perform a paired t-test to compare the activation values between the foreground and background\n",
    "t_stat, p_value = ttest_rel(foreground_vals, background_vals, nan_policy='omit')\n",
    "\n",
    "# Calculate the differences between foreground and background activation values\n",
    "differences = foreground_vals - background_vals\n",
    "# Compute the mean of the differences\n",
    "mean_diff = np.nanmean(differences)\n",
    "# Compute the standard deviation of the differences (with degrees of freedom correction, ddof=1)\n",
    "std_diff = np.nanstd(differences, ddof=1) # use chatgpt-4o on 2/5/2025 at 8:30pm\n",
    "# Calculate Cohen's d effect size\n",
    "cohens_d = mean_diff / std_diff\n",
    "\n",
    "print(\"paired t-test result：\")\n",
    "print(f\"t = {t_stat:.3f}, p = {p_value:.3f}\")\n",
    "print(f\"Cohen's d = {cohens_d:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUFUca-o2LlB"
   },
   "source": [
    "* We can see that the paired t-test results in a t-value of 14.755 with a p-value of 0.000 (p < 0.001), indicating that the difference between the paired samples is highly statistically significant. Therefore, we we reject the null hypothesis H₀ and conclude that the foreground activations are significantly higher than the background activations. (t statistic is significantly positive)\n",
    "* Additionally, Cohen's d of 2.608 reflects a very large effect size, meaning that the magnitude of the difference is not only statistically reliable but also practically substantial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hpom1kGsnGK"
   },
   "source": [
    "### **Step 5**: Visualize a few example images with Grad-CAM heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of examples to visualize\n",
    "num_examples = 5\n",
    "for example in visualization_examples[:num_examples]:\n",
    "    fname = example['filename']\n",
    "    original = example['original']\n",
    "    heatmap = example['heatmap']\n",
    "    mask = example['mask']\n",
    "\n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Show the original image on the left subplot\n",
    "    vis_img = original.copy()\n",
    "    draw = ImageDraw.Draw(vis_img)\n",
    "    ax[0].imshow(vis_img)\n",
    "    ax[0].set_title(f\"{fname} - Original image\")\n",
    "    ax[0].axis('off') # refine by chatgpt-4o on 2/5/2025 at 9:00pm\n",
    "\n",
    "    # Right subplot displays the Grad-CAM heatmap overlaid on the original image\n",
    "    ax[1].imshow(original, alpha=0.6)\n",
    "    ax[1].imshow(heatmap, cmap='jet', alpha=0.4)\n",
    "    ax[1].set_title(f\"{fname} - Grad-CAM heatmap\")\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15QSBHww5AFg"
   },
   "source": [
    "* If HO were true, we would expect evenly distributed activation across both foreground and background.\n",
    "* However, from the Grad-CAM heatmaps, we can see the model primarily focuses on key airplane structures, such as the cockpit, engines, tail, and fuselage, indicating that these areas play an important role in classification.\n",
    "* Background regions such as the sky, runway, and buildings show lower activation, suggesting that the model does not heavily rely on background cues.\n",
    "* In some cases, the model pays attention to branding elements like logos, airline names..., which may indicate additional features influencing classification. However, these elements are still part of the airplane, further suggesting that the model focuses on the foreground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nR2K8Vsz50Jp"
   },
   "source": [
    "### **Summary: Rejecting H0 & in favor of H1**\n",
    "\n",
    "✅ Since both the Grad-CAM visualizations and the statistical test show that the model focuses on the airplane rather than the background ( Foreground activations are significantly higher than background activations, both visually and statistically ), we reject **H0** and accept **H1**.\n",
    "\n",
    "✅ This means the model is correctly learning to classify airplanes based on airplane-related features ( object features ), not background artifacts.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
